---
format:
  html:
    code-fold: false #show
jupyter: python3
execute:
  cache: true # re-render only when source changes
---

# Column Operations


In this chapter we will focus on column operations, including dropping, renaming, and mapping columns.

For these examples, we will use a familiar dataset of products:

```{python}
#|code-fold: show

from pandas import read_csv

request_url = "https://raw.githubusercontent.com/prof-rossetti/intro-to-python/main/data/products.csv"
df = read_csv(request_url)
df.head()
```


## `Series` as a Column

Remember, when we access a given column of values, we are working with a `Series` object:

```{python}
prices = df["price"]
print(type(prices))
prices
```

With a `Series` object as a column, we can use list-like accessors to access one of the values based on its row index value:

```{python}
prices[0]
```

And we can convert the `Series` object to a normal list as desired:

```{python}
print(prices.tolist())
```

### Series Aggregations

One of the cool things about `Series` objects is they know how to calculate their own aggregations.

For example, minimum and maximum values:

```{python}
print("MIN PRICE:", df["price"].min())
print("MAX PRICE:", df["price"].max())
```

Mean and median values:

```{python}
print("MEAN PRICE:", df["price"].mean().round(2))
print("MEDIAN PRICE:", df["price"].median().round(2))
```

Percentiles, etc:

```{python}
print("25TH PCT PRICE:", df["price"].quantile(.25).round(2))
print("75TH PCT PRICE:", df["price"].quantile(.75).round(2))
```


### Value Counts

The `value_counts` method shows us a count of the number of rows for each value in a given column:

```{python}
df["department"].value_counts()
```

We can use the `normalize` parameter to display our counts as percentage of the total number of rows:

```{python}
df["department"].value_counts(normalize=True)
```



## Renaming Columns

We can use the [`rename` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html) to rename columns. This is not mutating unless we use the `inplace` parameter.


```{python}
df.rename(columns={"department": "dept"}, inplace=True)
df.head()
```

## Dropping Columns

We can use the [`drop` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) to remove columns from the dataset. This is not mutating unless we use the `inplace` parameter.


```{python}
df.drop(columns=["aisle"], inplace=True)
df.head()
```

## Creating New Columns

We can create a new column by specifying the name of that column and assigning a new value. For example, a column of constants:

```{python}
df["inflation_factor"] = 1.5

df.head()
```

In practice, instead of creating a new column of constants or placeholder values, we will generally create a new column of transformed values (see "Mapping Columns" section below).


## Mapping Columns

We can transform the values in one given column, and store the results in another column

When mapping using a single scalar value, for example multiplying all values in a column by 1.5:

```{python}
# PRICE COL * 1.5
df["inflated_price"] = (df["price"] * 1.5).round(2)

df[["id", "name", "price", "inflated_price"]].head()
```

When mapping using two columns, this performs an element-wise operation where the first values in each `Series` are compared, then the second values, etc.


```{python}
# PRICE COL * INFLATION FACTOR COL
df["inflated_price"] = (df["price"] * df["inflation_factor"]).round(2)

df[["id", "name", "price", "inflation_factor", "inflated_price"]].head()
```


This essentially allows us to compare multiple values from the same row.






### Applying a Mapping Dictionary

If we want to change certain values, we can use the [`map` method](https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html) in conjunction with a dictionary to provide the mapping of old values to new values:

```{python}
department_abbrevs = {
  "beverages": "BV",
  "frozen": "FR",
  "pantry": "PN",
  "snacks": "SN",
  "personal care": "PC",
  "dairy eggs": "DE",
  "household": "HH",
  "babies": "BB",
  "meat seafood": "MS",
  "dry goods pasta": "DG",
} # DEFINE VALUE MAPPING

df["dept_abbrev"] = df["dept"].map(department_abbrevs) # APPLY VALUE MAPPING

df[["id", "name", "dept", "dept_abbrev"]].head()
```

In this example, we are using the `department_abbrevs` dictionary to look up the corresponding abbreviation for each department name in the "dept" column. As a result we obtain a new column of transformed values (the abbreviations), which we are storing back in the original `DataFrame` in a new column called "dept_abbrev".


### Applying a Transformation Function

For more complex mapping logic, we can use the [`apply` method](https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html) to apply a transformation function.

When defining our own transformation function, the function should accept a parameter representing one of the values in the column over which we are applying the function. It should operate on that input value and return the transformed value.

```{python}
# TRANSFORMATION FUNCTION:

def inflate_price(original_price):
    # only inflate if the price is greater than $5
    if original_price < 5.00:
        return original_price
    else:
        return original_price * 1.5

assert inflate_price(3.00) == 3.00
assert inflate_price(10.00) == 15.00
```


After defining the transformation function, we pass that function as a parameter to the `apply` method:

```{python}
# APPLY TRANSFORMATION FUNCTION TO PRICE COL:
df["inflated_price"] = df["price"].apply(inflate_price).round(2)

df[["id", "name", "price", "inflated_price"]].head()
```

In this example, we are applying the transformation function `inflate_price` to each value in the "price" column. As a result we obtain a new column of transformed values, which we are storing back in the original `DataFrame` in a new column called "inflated_price".
