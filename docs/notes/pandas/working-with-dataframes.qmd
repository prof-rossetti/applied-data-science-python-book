

# Working with DataFrames

To continue working with DataFrames, lets consider this dataframe of products:


```{python}
from pandas import read_csv

request_url = ("https://raw.githubusercontent.com/"
                "prof-rossetti/intro-to-python/"
                "main/data/products.csv")
df = read_csv(request_url)
print(type(df))
df.head()
```


Now that we have obtained a dataframe, let's start working with it.

## Previewing the Data

We can preview the first few rows, or the last few rows, using the `head` or `tail` method, respectively:

```{python}
df.head()
```

```{python}
df.tail()
```

By default, we see five rows, but we can customize the number of rows by passing an integer parameter to these methods, like `head(3)`.

## Dataset Size and Shape

Counting number of rows, by passing the dataframe to the familiar `len` function:

```{python}
len(df) #> int of n_rows
```


Using the `shape` property is especially helpful when working with multidimensional data (i.e. data in three or more dimensions).

```{python}
df.shape #> tuple of (n_rows, n_cols)
```

## Index

Be aware, every dataframe has an index (or set of unique row identifiers). By default the index is a set of auto-incrementing numbers starting at 0.

```{python}
df.index
```

## Accessing Rows

We use a list-like accessor approach to reference a given row, using the `iloc` method.

When we access a single row, we get a `Series` object. In this example, we are accessing the first row, using an index value of `0`:

```{python}
first_row = df.iloc[0]
print(type(first_row)) #> Series

first_row
```

When we access multiple rows, we get a `DataFrame` object. In this example, we are accessing the first three rows, using a slicing approach:

```{python}
first_rows = df.iloc[0:3]
print(type(first_rows)) #> Series

first_rows
```

:::{.callout-note title="Note"}
When we use index references, we are actually referencing the index value itself (which by default is an auto-incrementing integer starting at zero). But its possible for us the change the index (for example the date). So if you change your index later, you may need to use the new index values (dates instead of the default integers).
:::

### Iteration / Looping through Rows


We can loop through each row using the [`iterrows` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html), involving a destructuring approach to reference the row index (`i`) as well as the row's values (`row`).

In this example, we are looping through just the first three rows, for simplicity:


```{python}
for i, row in df.head(3).iterrows():
    print("------------")
    print("INDEX:", i)
    print(type(row))
    print(row)
    #print(row["timestamp"])
```

When we reference a given row in this approach, we are dealing with a `Series` object.

## Sorting Rows

We can use the DataFrame's [`sort_values` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html
 ) to sort rows on the basis of one or more given columns.

By default, `sort_values` is not mutating, but as of the current version of `pandas`, we can use the `inplace` parameter to perform a mutating sort:


```
# can store back in same variable to overwrite:
# prices_df = prices_df.sort_values(by="timestamp", ascending=True)

# or alternatively use inplace=True parameter to perform a MUTATING operations
prices_df.sort_values(by="timestamp", ascending=True, inplace=True)
prices_df.head()
```

We can use the `ascending` parameter to reverse the sort order:

```
prices_df.sort_values(by="timestamp", ascending=False, inplace=True)
prices_df.head()
```

## Column Names

Identifying column names, using the `columns` property:

```
df.columns
```

```
df.columns.tolist()
```


## Accessing Columns

We can access one or more columns worth of values, using a dictionary-like accessor.

When we access a single column (using a string column name), we get a pandas `Series` object:

```
df["name"]
```

When we access multiple columns (using a list of column names), we get a `DataFrame` object back:

```
closing_prices = prices_df[["timestamp", "adjusted_close", "volume"]]
print(type(closing_prices)) #> DataFrame

closing_prices.head()
```

## Filtering Rows

We can filter a `DataFrame` to get only the rows that match some given condition.

We first specify a "mask" condition that determines for each row, whether it meet the criteria or not (True vs False).

```
# this is the mask:
prices_df["timestamp"] == "2021-10-15"
```

Filtering based on equality, using familiar `==` operator:

```
prices_df[  prices_df["timestamp"] == "2021-10-15" ]
```

Filtering based on numeric comparisons:

```
prices_df[  prices_df["timestamp"] >= "2021-10-12" ]
```

Filtering based on values between lower and upper bound, using `between` method:

```
prices_df[  prices_df["timestamp"].between("2021-10-01", "2021-11-01") ]
```


Filtering based on inclusion, using `isin` method:

```
dates_of_interest = ["2021-10-15", "2021-10-14", "2021-10-12"]

prices_df[  prices_df["timestamp"].isin(dates_of_interest) ]
```

Filtering on substring match, using `str.contains` method:

```
prices_df[  prices_df["timestamp"].str.contains("2021-10-1") ]
```

## Saving Data to CSV File

We can use the [`to_csv` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) to export a `DataFrame` to a CSV file. When we do this, we specify as a parameter the name of the CSV file that should be created:

```
# run this cell then check the colab notebook filesystem, where you can see the file and download it
prices_df.to_csv("prices_export.csv", index=False)
```

When saving files in Colab, the file will be saved to the Colab Filesystem, where we have the ability to download the file to our local machine.
